{
  "dataset_revision": "main",
  "task_name": "TurkishOffensiveLanguageClassification",
  "mteb_version": "1.31.3",
  "scores": {
    "test": [
      {
        "accuracy": 0.586259,
        "f1": 0.516246,
        "f1_weighted": 0.623298,
        "ap": 0.22878,
        "ap_weighted": 0.22878,
        "scores_per_experiment": [
          {
            "accuracy": 0.574111,
            "f1": 0.509001,
            "f1_weighted": 0.615466,
            "ap": 0.222958,
            "ap_weighted": 0.222958
          },
          {
            "accuracy": 0.589189,
            "f1": 0.515477,
            "f1_weighted": 0.628008,
            "ap": 0.222935,
            "ap_weighted": 0.222935
          },
          {
            "accuracy": 0.549075,
            "f1": 0.522312,
            "f1_weighted": 0.589639,
            "ap": 0.261053,
            "ap_weighted": 0.261053
          },
          {
            "accuracy": 0.5266,
            "f1": 0.486789,
            "f1_weighted": 0.571902,
            "ap": 0.224737,
            "ap_weighted": 0.224737
          },
          {
            "accuracy": 0.511522,
            "f1": 0.464261,
            "f1_weighted": 0.559009,
            "ap": 0.208601,
            "ap_weighted": 0.208601
          },
          {
            "accuracy": 0.621622,
            "f1": 0.53833,
            "f1_weighted": 0.655094,
            "ap": 0.232275,
            "ap_weighted": 0.232275
          },
          {
            "accuracy": 0.613656,
            "f1": 0.538179,
            "f1_weighted": 0.649349,
            "ap": 0.235304,
            "ap_weighted": 0.235304
          },
          {
            "accuracy": 0.647511,
            "f1": 0.510424,
            "f1_weighted": 0.664683,
            "ap": 0.20756,
            "ap_weighted": 0.20756
          },
          {
            "accuracy": 0.643528,
            "f1": 0.561004,
            "f1_weighted": 0.674339,
            "ap": 0.246912,
            "ap_weighted": 0.246912
          },
          {
            "accuracy": 0.585775,
            "f1": 0.516683,
            "f1_weighted": 0.625494,
            "ap": 0.22547,
            "ap_weighted": 0.22547
          }
        ],
        "main_score": 0.586259,
        "hf_subset": "default",
        "languages": [
          "tur-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 66.191654920578,
  "kg_co2_emissions": null
}