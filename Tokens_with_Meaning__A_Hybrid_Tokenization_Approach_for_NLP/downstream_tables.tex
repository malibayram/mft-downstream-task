% Auto-curated tables for downstream evaluation (STS + MTEB).

\begin{table}[H]
\centering
\caption{Turkish STS benchmark (STSb-TR) results. Pearson/Spearman are computed on the test split (1,379 pairs).}
\label{tab:sts_results}
\begin{tabular}{lcc}
\toprule
Model & Pearson (\%) & Spearman (\%) \\
\midrule
MFT-Magibu & \textbf{74.41} & \textbf{73.08} \\
MFT-Gemma  & 71.02 & 70.00 \\
Tabi-Magibu & 66.29 & 64.97 \\
Tabi-Gemma  & 61.54 & 60.56 \\
\midrule
MFT-RandomInit  & 47.09 & 45.96 \\
Tabi-RandomInit & 40.53 & 38.60 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{MTEB-TR summary (26 tasks). We report the overall average and category averages from the repository report.}
\label{tab:mteb_summary}
\begin{tabular}{lccc}
\toprule
Model & Overall Avg (\%) & Retrieval Avg (\%) & STS Avg (\%) \\
\midrule
MFT-Gemma   & 62.09 & \textbf{65.90} & 72.94 \\
MFT-Magibu  & 61.83 & 64.39 & \textbf{74.73} \\
Tabi-Gemma  & 62.36 & 65.73 & 71.47 \\
Tabi-Magibu & \textbf{62.59} & 65.46 & 72.41 \\
\midrule
MFT-RandomInit  & 38.99 & 28.94 & 49.36 \\
Tabi-RandomInit & 33.33 & 18.46 & 33.24 \\
\bottomrule
\end{tabular}
\end{table}
