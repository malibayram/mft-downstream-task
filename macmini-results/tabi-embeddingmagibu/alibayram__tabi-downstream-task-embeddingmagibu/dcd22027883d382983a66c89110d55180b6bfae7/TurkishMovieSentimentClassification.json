{
  "dataset_revision": "409a4415cce5f6bcfca6d5f3ca3c408211ca00b3",
  "task_name": "TurkishMovieSentimentClassification",
  "mteb_version": "1.31.3",
  "scores": {
    "test": [
      {
        "accuracy": 0.618896,
        "f1": 0.615266,
        "f1_weighted": 0.615266,
        "ap": 0.575256,
        "ap_weighted": 0.575256,
        "scores_per_experiment": [
          {
            "accuracy": 0.574219,
            "f1": 0.562585,
            "f1_weighted": 0.562585,
            "ap": 0.545284,
            "ap_weighted": 0.545284
          },
          {
            "accuracy": 0.632812,
            "f1": 0.632251,
            "f1_weighted": 0.632251,
            "ap": 0.582767,
            "ap_weighted": 0.582767
          },
          {
            "accuracy": 0.643066,
            "f1": 0.642297,
            "f1_weighted": 0.642297,
            "ap": 0.594094,
            "ap_weighted": 0.594094
          },
          {
            "accuracy": 0.637207,
            "f1": 0.637203,
            "f1_weighted": 0.637203,
            "ap": 0.587301,
            "ap_weighted": 0.587301
          },
          {
            "accuracy": 0.615234,
            "f1": 0.614704,
            "f1_weighted": 0.614704,
            "ap": 0.571961,
            "ap_weighted": 0.571961
          },
          {
            "accuracy": 0.649414,
            "f1": 0.640069,
            "f1_weighted": 0.640069,
            "ap": 0.607647,
            "ap_weighted": 0.607647
          },
          {
            "accuracy": 0.628418,
            "f1": 0.618202,
            "f1_weighted": 0.618202,
            "ap": 0.576635,
            "ap_weighted": 0.576635
          },
          {
            "accuracy": 0.624512,
            "f1": 0.624376,
            "f1_weighted": 0.624376,
            "ap": 0.57719,
            "ap_weighted": 0.57719
          },
          {
            "accuracy": 0.55957,
            "f1": 0.558201,
            "f1_weighted": 0.558201,
            "ap": 0.533778,
            "ap_weighted": 0.533778
          },
          {
            "accuracy": 0.624512,
            "f1": 0.622774,
            "f1_weighted": 0.622774,
            "ap": 0.575906,
            "ap_weighted": 0.575906
          }
        ],
        "main_score": 0.618896,
        "hf_subset": "default",
        "languages": [
          "tur-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 25.96808695793152,
  "kg_co2_emissions": null
}