{
  "dataset_revision": "main",
  "task_name": "TurkishIronyClassification",
  "mteb_version": "1.31.3",
  "scores": {
    "test": [
      {
        "accuracy": 0.501667,
        "f1": 0.493666,
        "f1_weighted": 0.493666,
        "ap": 0.502155,
        "ap_weighted": 0.502155,
        "scores_per_experiment": [
          {
            "accuracy": 0.55,
            "f1": 0.546853,
            "f1_weighted": 0.546853,
            "ap": 0.527143,
            "ap_weighted": 0.527143
          },
          {
            "accuracy": 0.425,
            "f1": 0.418172,
            "f1_weighted": 0.418172,
            "ap": 0.467123,
            "ap_weighted": 0.467123
          },
          {
            "accuracy": 0.55,
            "f1": 0.547991,
            "f1_weighted": 0.547991,
            "ap": 0.527885,
            "ap_weighted": 0.527885
          },
          {
            "accuracy": 0.525,
            "f1": 0.522313,
            "f1_weighted": 0.522313,
            "ap": 0.513235,
            "ap_weighted": 0.513235
          },
          {
            "accuracy": 0.508333,
            "f1": 0.507478,
            "f1_weighted": 0.507478,
            "ap": 0.504242,
            "ap_weighted": 0.504242
          },
          {
            "accuracy": 0.525,
            "f1": 0.512786,
            "f1_weighted": 0.512786,
            "ap": 0.513415,
            "ap_weighted": 0.513415
          },
          {
            "accuracy": 0.491667,
            "f1": 0.491349,
            "f1_weighted": 0.491349,
            "ap": 0.495906,
            "ap_weighted": 0.495906
          },
          {
            "accuracy": 0.466667,
            "f1": 0.459307,
            "f1_weighted": 0.459307,
            "ap": 0.484783,
            "ap_weighted": 0.484783
          },
          {
            "accuracy": 0.491667,
            "f1": 0.468603,
            "f1_weighted": 0.468603,
            "ap": 0.495952,
            "ap_weighted": 0.495952
          },
          {
            "accuracy": 0.483333,
            "f1": 0.461806,
            "f1_weighted": 0.461806,
            "ap": 0.491865,
            "ap_weighted": 0.491865
          }
        ],
        "main_score": 0.501667,
        "hf_subset": "default",
        "languages": [
          "tur-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.618151903152466,
  "kg_co2_emissions": null
}